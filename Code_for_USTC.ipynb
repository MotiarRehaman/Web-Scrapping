{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paris\n",
      "Venezia\n",
      "London\n",
      "Antwerpen\n",
      "Lyon\n",
      "Roma\n",
      "Wittenberg\n",
      "Leipzig\n",
      "Köln\n",
      "Strasbourg\n",
      "Nürnberg\n",
      "Basel\n",
      "Bologna\n",
      "Madrid\n",
      "Amsterdam\n",
      "Leiden\n",
      "Jena\n",
      "Augsburg\n",
      "Firenze\n",
      "Milano\n",
      "Rouen\n",
      "Frankfurt am Main\n",
      "Barcelona\n",
      "Erfurt\n",
      "Napoli\n",
      "Sevilla\n",
      "Rostock\n",
      "Lisboa\n",
      "Magdeburg\n",
      "Gene\n",
      "Helmstedt\n",
      "Genève\n",
      "Ingolstadt\n",
      "Louvain\n",
      "Douai\n",
      "Valencia\n",
      "Den Haag\n",
      "Salamanca\n",
      "Zaragoza\n",
      "Kraków\n",
      "Marburg\n",
      "Bruxelles\n",
      "Dresden\n",
      "Brescia\n",
      "Mainz\n",
      "Padova\n",
      "Zürich\n",
      "Alcalá de Henares\n",
      "Wien\n",
      "Hamburg\n",
      "München\n",
      "Frankfurt an der Oder\n",
      "Heidelberg\n",
      "Toulouse\n",
      "Granada\n",
      "Torino\n",
      "Deventer\n",
      "Valladolid\n",
      "Utrecht\n",
      "Altdorf\n",
      "Poitiers\n",
      "Bordeaux\n",
      "Praha\n",
      "Ferrara\n",
      "Gent\n",
      "Lübeck\n",
      "Siena\n",
      "Verona\n",
      "Delft\n",
      "Pavia\n",
      "Dillingen\n",
      "Wolfenbüttel\n",
      "Wrocław\n",
      "México\n",
      "Franeker\n",
      "Coburg\n",
      "Troyes\n",
      "Eisleben\n",
      "Liège\n",
      "Haarlem\n",
      "Perugia\n",
      "Burgos\n",
      "Toledo\n",
      "Rotterdam\n",
      "Groningen\n",
      "København\n",
      "Vicenza\n",
      "Ulm\n",
      "Oxford\n",
      "Palermo\n",
      "Middelburg\n",
      "Hanau\n",
      "Speyer\n",
      "Genova\n",
      "Orléans\n",
      "Freiberg\n",
      "Dordrecht\n",
      "Görlitz\n",
      "Coimbra\n",
      "Caen\n",
      "Edinburgh\n",
      "Regensburg\n",
      "Braunschweig\n",
      "La Rochelle\n",
      "Treviso\n",
      "Herborn\n",
      "Parma\n",
      "Berlin\n",
      "Zwickau\n",
      "Aix-en-Provence\n",
      "Cambridge\n",
      "Mantova\n",
      "Lima\n",
      "Zerbst\n",
      "Tours\n",
      "Macerata\n",
      "Kaliningrad\n",
      "Haguenau\n",
      "Altenburg\n",
      "Lauingen\n",
      "Amberg\n",
      "Piacenza\n",
      "Würzburg\n",
      "Cremona\n",
      "Bremen\n",
      "Mühlhausen\n",
      "Reims\n",
      "Viterbo\n",
      "Modena\n",
      "Bergamo\n",
      "Greifswald\n",
      "Medina del Campo\n",
      "Lüneburg\n",
      "Arras\n",
      "Stockholm\n",
      "Saumur\n",
      "Messina\n",
      "Angers\n",
      "Mons\n",
      "Emden\n",
      "Leeuwarden\n",
      "Lille\n",
      "Pamplona\n",
      "Freiburg im Breisgau\n",
      "Gouda\n",
      "Schmalkalden\n",
      "Oberursel\n",
      "Arnhem\n",
      "Kassel\n",
      "Montpellier\n",
      "Münster\n",
      "Hof\n",
      "Graz\n",
      "Lucca\n",
      "Neustadt an der Weinstraße\n",
      "Bautzen\n",
      "Halberstadt\n",
      "'s-Hertogenbosch\n",
      "Konstanz\n",
      "Bamberg\n",
      "Bern\n",
      "GdaÃsk\n",
      "Kampen\n",
      "Pesaro\n",
      "Zwolle\n",
      "Sedan\n",
      "Córdoba\n",
      "Rennes\n",
      "Schleusingen\n",
      "Brugge\n",
      "Tournai\n",
      "Hildesheim\n",
      "Hoorn\n",
      "Cuenca\n",
      "Montbéliard\n",
      "Avignon\n",
      "Le Mans\n",
      "Lemgo\n",
      "Pont-à-Mousson\n",
      "Tournon\n",
      "Limoges\n",
      "Westminster\n",
      "Worms\n",
      "La Flèche\n",
      "Dublin\n",
      "Metz\n",
      "Szczecin\n",
      "Málaga\n",
      "Oppenheim\n",
      "Dijon\n",
      "Reutlingen\n",
      "Halle\n",
      "Landshut\n",
      "Ravenna\n",
      "Orvieto\n",
      "Cluj\n",
      "Bourges\n",
      "Salzburg\n",
      "Stuttgart\n",
      "Nancy\n",
      "Huesca\n",
      "Reggio Emilia\n",
      "Udine\n",
      "Cesena\n",
      "Ancona\n",
      "Uelzen\n",
      "Évora\n",
      "Vercelli\n",
      "Chambéry\n",
      "Schleswig\n",
      "Gotha\n",
      "Memmingen\n",
      "Innsbruck\n",
      "Wesel\n",
      "Nantes\n",
      "Mondovì\n",
      "Cagliari\n",
      "Neisse\n",
      "Rimini\n",
      "Debrecen\n",
      "Passau\n",
      "Logroño\n",
      "Trino\n",
      "Cahors\n",
      "Grenoble\n",
      "Ieper\n",
      "Palma de Mallorca\n",
      "Urbino\n",
      "Lérida\n",
      "Harderwijk\n",
      "Pisa\n",
      "Alkmaar\n",
      "Novara\n",
      "Düsseldorf\n",
      "Foligno\n",
      "Pforzheim\n",
      "Olomouc\n",
      "Poznań\n",
      "Legnica\n",
      "Vienne\n",
      "Cambrai\n",
      "Hannover\n",
      "Nîmes\n",
      "Dortmund\n",
      "Mechelen\n",
      "Toul\n",
      "Montauban\n",
      "York\n",
      "Camerino\n",
      "Nijmegen\n",
      "Como\n",
      "Trento\n",
      "Cádiz\n",
      "Angoulême\n",
      "Lich\n",
      "Bardejov\n",
      "Fermo\n",
      "Châlons-en-Champagne\n",
      "Lausanne\n",
      "Enkhuizen\n",
      "Verdun\n",
      "Straubing\n",
      "Brașov\n",
      "Valenciennes\n",
      "Litomyšl\n",
      "Alessandria\n",
      "Blois\n",
      "Trier\n",
      "Murcia\n",
      "Schwäbisch Hall\n",
      "Casale Monferrato\n",
      "Manila\n",
      "Tarragona\n",
      "Girona\n",
      "Toruń\n",
      "Southwark\n",
      "Elbing\n",
      "Asti\n",
      "Niort\n",
      "Agen\n",
      "L'Aquila\n",
      "Chartres\n",
      "Fano\n",
      "Antequera\n",
      "Perpignan\n",
      "Prostějov\n",
      "Braga\n",
      "Schweinfurt\n",
      "Langres\n",
      "Sens\n",
      "Carmagnola\n",
      "Zittau\n",
      "Toscolano\n",
      "Breda\n",
      "Zweibrücken\n",
      "Güstrow\n",
      "Siegen\n",
      "Rees\n",
      "Segovia\n",
      "Trnava\n",
      "Tortona\n",
      "Mulhouse\n",
      "Castres\n",
      "Gorinchem\n",
      "Sélestat\n",
      "Fribourg\n",
      "Vianen\n",
      "Malmö\n",
      "Schiedam\n",
      "Ipswich\n",
      "Tegernsee\n",
      "Plzeň\n",
      "Luzern\n",
      "Rorschach\n",
      "Besançon\n",
      "Vico Equense\n",
      "Pistoia\n",
      "Schoonhoven\n",
      "Riva\n",
      "Lodi\n",
      "Forlì\n",
      "Urach\n",
      "Bergerac\n",
      "Tortosa\n",
      "Périgueux\n",
      "Colmar\n",
      "Steenwijk\n",
      "Nördlingen\n",
      "Zamora\n",
      "Dole\n",
      "Paderborn\n",
      "Esslingen\n",
      "Faenza\n",
      "Luxembourg\n",
      "Torgau\n",
      "Thierhaupten\n",
      "Bilbao\n",
      "Cosenza\n",
      "Morges\n",
      "Estella\n",
      "Oporto\n",
      "Bonn\n",
      "Alençon\n",
      "Kralice\n",
      "Barth\n",
      "Montserrat\n",
      "Ascoli Piceno\n",
      "Eilenburg\n",
      "Mladá Boleslav\n",
      "Saint-Gervais\n",
      "Rothenburg ob der Tauber\n",
      "Amiens\n",
      "Vilnius\n",
      "Mansfeld\n",
      "Nevers\n",
      "Pescia\n",
      "Weißenfels\n",
      "Sibiu\n",
      "Annecy\n",
      "Baeza\n",
      "Clermont\n",
      "Belluno\n",
      "Neuburg an der Donau\n",
      "Uppsala\n",
      "Raków\n",
      "Soncino\n",
      "Todi\n",
      "Casalmaggiore\n",
      "Sankt Gallen\n",
      "Valence\n",
      "Solingen\n",
      "Orthez\n",
      "Tulle\n",
      "Canterbury\n",
      "Albi\n",
      "Alba Iulia\n",
      "Emmerich\n",
      "Melun\n",
      "Frankenthal\n",
      "Alost\n",
      "Durlach\n",
      "Güssing\n",
      "Brno\n",
      "Narbonne\n",
      "Chieti\n",
      "Fossombrone\n",
      "Poschiavo\n",
      "Neudamm\n",
      "Spoleto\n",
      "Blaubeuren\n",
      "Brześć\n",
      "Huete\n",
      "Saint-Nicolas-de-Port\n",
      "Oldenburg\n",
      "Pont-Audemer\n",
      "Saintes\n",
      "Loreto\n",
      "Eichstätt\n",
      "Marienthal\n",
      "Le Puy\n",
      "Marseille\n",
      "Braniewo\n",
      "Lindau\n",
      "Guadalajara\n",
      "Salz\n",
      "Lviv\n",
      "Jesi\n",
      "Dieppe\n",
      "Ivančice\n",
      "Biella\n",
      "Campagna\n",
      "Simmern\n",
      "Viborg\n",
      "Warszawa\n",
      "Saint-Lô\n",
      "Varallo\n",
      "Neufchâtel\n",
      "Ivrea\n",
      "Worcester\n",
      "Catania\n",
      "Sanlucar a Barrameda\n",
      "St Andrews\n",
      "Ettlingen\n",
      "Soest\n",
      "Savona\n",
      "Assisi\n",
      "Maastricht\n",
      "Bressanone\n",
      "Arezzo\n",
      "Collio\n",
      "Goa\n",
      "Cuneo\n",
      "Sorau\n",
      "Bari\n",
      "Pons\n",
      "Harlingen\n",
      "Eberau\n",
      "Pontorson\n",
      "Homberg\n",
      "Provins\n",
      "Groessen\n",
      "Grodzisk\n",
      "Osuna\n",
      "Norwich\n",
      "St Albans\n",
      "Sich\n",
      "Leon\n",
      "Astorga\n",
      "Eger\n",
      "Burgsteinfurt\n",
      "Uraniborg\n",
      "Città di Castello\n",
      "Eisenach\n",
      "Vizsoly\n",
      "Bratislava\n",
      "Isny\n",
      "Auxerre\n",
      "Morlaix\n",
      "Aachen\n",
      "Grimma\n",
      "Sant'Orso\n",
      "Oudenaarde\n",
      "Carpi\n",
      "Pinerolo\n",
      "Pińczów\n",
      "Schwaz\n",
      "Gaeta\n",
      "Plavecký hrad\n",
      "Bréhan-Loudéac\n",
      "Fabriano\n",
      "Orense\n",
      "Hijar\n",
      "Merseburg\n",
      "Saint-Denis\n",
      "Tivoli\n",
      "Annaberg\n",
      "Zamość\n",
      "Palencia\n",
      "Roskilde\n",
      "Tréguier\n"
     ]
    }
   ],
   "source": [
    "# Creating a list of places\n",
    "\n",
    "PLACES = []\n",
    "places_excel = pd.read_excel('USTC_cities.xlsx')\n",
    "\n",
    "for i in range(len(places_excel)):\n",
    "    PLACES.append(places_excel['finalname'][i])\n",
    "    print(places_excel['finalname'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n"
     ]
    }
   ],
   "source": [
    "print(len(PLACES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n"
     ]
    }
   ],
   "source": [
    "# Loop for place and counts \n",
    "\n",
    "sample_url_rps = 'https://api.ustc.ac.uk/api//editions?&qdate=1451-1600&qo=0,0,1&qp=1&fqPl=Paris&fqSb=Travel'\n",
    "sample_url_rp  = 'https://api.ustc.ac.uk/api//editions?&qdate=1451-1600&qo=0,0,1&qp=1&fqPl='\n",
    "\n",
    "range_var = 'qdate'\n",
    "place_var = '&fqPl'\n",
    "sub_var   = '&fqSb'\n",
    "\n",
    "\n",
    "list_of_tup = []\n",
    "#list_of_tup_with_subjects = []\n",
    "\n",
    "# Scrapping the json file \n",
    "\n",
    "\n",
    "for i in range(len(PLACES)):\n",
    "    url  = 'https://api.ustc.ac.uk/api//editions?&qdate=1451-1600&qo=0,0,1&qp=1&fqPl=' + str(PLACES[i])\n",
    "    data = requests.get(url).json()\n",
    "    Dict = data['meta']['facets']['interval']\n",
    "    list_of_tup.append((Dict, PLACES[i]))\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "# Formatting the files    \n",
    "    \n",
    "for i in range(len(list_of_tup)):\n",
    "    temp = list_of_tup[i]\n",
    "    \n",
    "    place = temp[1]\n",
    "    trend = temp[0]\n",
    "\n",
    "    year = []\n",
    "    counts = []\n",
    "    place1 = []\n",
    "    \n",
    "    for key,val in trend.items():\n",
    "        \n",
    "\n",
    "        year.append(key)\n",
    "        counts.append(trend[key])\n",
    "        place1.append(place)\n",
    "        \n",
    "    year   = np.array(year)\n",
    "    counts = np.array(counts)\n",
    "    place1 = np.array(place1)\n",
    "\n",
    "    year   = year.reshape((len(year),1))\n",
    "    counts = counts.reshape((len(counts),1))\n",
    "    place1 = place1.reshape((len(place1),1))\n",
    "\n",
    "    temp_data = np.concatenate((place1, year, counts), axis =1)\n",
    "    dataframe = pd.DataFrame(data = temp_data, columns = ['Place', 'Year', 'Count'])\n",
    "    dataframe = dataframe.sort_values(by = 'Year')\n",
    "\n",
    "    if i == 0:\n",
    "        final_dataframe = dataframe.copy()\n",
    "    else:\n",
    "        final_dataframe = pd.concat([final_dataframe, dataframe], axis=0)       \n",
    "        final_dataframe.reset_index(drop = True, inplace= True)\n",
    "        \n",
    "        \n",
    "    print(i)\n",
    "\n",
    "    \n",
    "\n",
    "final_dataframe.to_csv('All_cities_1451-1600.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Loop for place counts and subjects \n",
    "\n",
    "# Getting the list of subjects\n",
    "\n",
    "Dict = {'Religious': 19820, 'Ordinances and Edicts': 9339, 'Classical Authors': 5922, 'Political Tracts': 5596, \n",
    "        'History and Chronicles': 3489, 'Jurisprudence': 3400, 'Poetry': 3388, 'Literature': 3270, 'Medical Texts': 2579, \n",
    "        'Music': 2310, 'News Books': 2256, 'Educational Books': 1879, 'Drama': 1422, 'Bibles (including parts)': 1365, \n",
    "        'Philosophy and Morality': 1289, 'Science and Mathematics': 946, 'Funeral orations': 714, 'Academic Dissertations': 689,\n",
    "        'Government and Political Theory': 641, 'Dialectics and Rhetoric': 596, 'Travel': 583, 'Dictionaries': 510, \n",
    "        'Calendars and Prognostications': 396, 'Astrology and Cosmography': 386, 'Agriculture': 301, \n",
    "        'Adages and Emblem books': 297, 'Economics': 285, 'Heraldic Works and Genealogies': 234, \n",
    "        'Military Handbooks': 225, 'Art and Architecture': 179, 'Linguistics and Philology': 169, 'Book Trade': 126, \n",
    "        'Witchcraft and Demonology': 81, 'Etiquette and Courtesy': 61, 'Culinary Arts': 38, 'Games and Recreations': 37,\n",
    "        'Wedding pamphlets': 21, 'Marriage, the debate on women': 1}\n",
    "\n",
    "SUBJECTS = []\n",
    "\n",
    "for key,val in Dict.items():\n",
    "    SUBJECTS.append(key)\n",
    "\n",
    "    \n",
    "    \n",
    "list_of_tup = []\n",
    "#list_of_tup_with_subjects = []\n",
    "\n",
    "#subjects = ['Science%20and%20Mathematics', 'Travel', 'Economics', 'News%20Books']\n",
    "            \n",
    "# Scrapping the json file\n",
    "\n",
    "# 0-50         started\n",
    "# 50-100     \n",
    "# 100-150    \n",
    "# 150-200    \n",
    "# 200-250    \n",
    "# 250-300    \n",
    "# 300-350    \n",
    "# 350-400    \n",
    "# 400-480    \n",
    "\n",
    "\n",
    "\n",
    "for m in range(50):\n",
    "    \n",
    "    \n",
    "    \n",
    "    for j in range(len(SUBJECTS)):\n",
    "        \n",
    "        url  = 'https://api.ustc.ac.uk/api//editions?&qdate=1451-1500&qo=0,0,1&qp=1&fqPl=' +  str(PLACES[m]) + '&fqSb=' + str(SUBJECTS[j])    \n",
    "        data = requests.get(url).json()\n",
    "        Dict = data['meta']['facets']['interval']\n",
    "        list_of_tup.append((Dict, PLACES[m], SUBJECTS[j]))\n",
    "        time.sleep(1)\n",
    "        \n",
    "    if m%10 == 0:\n",
    "        print(m)\n",
    "        \n",
    "print(len(list_of_tup))\n",
    "    \n",
    "\n",
    "\n",
    "# Formatting\n",
    "    \n",
    "for i in range(len(list_of_tup)):\n",
    "        \n",
    "    temp = list_of_tup[i]\n",
    "    place = temp[1]\n",
    "    trend = temp[0]\n",
    "    sub   = temp[2]\n",
    "        \n",
    "    year   = []\n",
    "    counts = []\n",
    "    place1 = []\n",
    "    subject= []\n",
    "\n",
    "    for key,val in trend.items():\n",
    "            \n",
    "        year.append(key)\n",
    "        counts.append(trend[key])\n",
    "        subject.append(sub)\n",
    "        place1.append(place)\n",
    "        \n",
    "    year   = np.array(year)\n",
    "    counts = np.array(counts)\n",
    "    place1 = np.array(place1)\n",
    "    subject= np.array(subject)\n",
    "\n",
    "    year   = year.reshape((len(year),1))\n",
    "    counts = counts.reshape((len(counts),1))\n",
    "    place1 = place1.reshape((len(place1),1))\n",
    "    subject= subject.reshape((len(subject),1))\n",
    "\n",
    "    temp_data = np.concatenate((place1, year, counts, subject), axis =1)\n",
    "    dataframe = pd.DataFrame(data = temp_data, columns = ['Place', 'Year', 'Count','Subject'])\n",
    "    dataframe = dataframe.sort_values(by = 'Year')\n",
    "\n",
    "    if i == 0:\n",
    "        final_dataframe = dataframe.copy()\n",
    "    else:\n",
    "        final_dataframe = pd.concat([final_dataframe, dataframe], axis=0)       \n",
    "        final_dataframe.reset_index(drop = True, inplace= True)\n",
    "         \n",
    "        \n",
    "    print(i)\n",
    "    \n",
    "    \n",
    "\n",
    "final_dataframe.to_csv('All_cities_1451-1500_with_all_subjects_50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n"
     ]
    }
   ],
   "source": [
    "# Getting additional data for 1451-1500 for all cities \n",
    "\n",
    "    \n",
    "list_of_tup = []\n",
    "#list_of_tup_with_subjects = []\n",
    "\n",
    "# Scrapping the json file \n",
    "\n",
    "for i in range(len(PLACES)):\n",
    "    url  = 'https://api.ustc.ac.uk/api//editions?&qdate=1451-1500&qo=0,0,1&qp=1&fqPl=' + str(PLACES[i])\n",
    "    data = requests.get(url).json()\n",
    "    Dict = data['meta']['facets']['interval']\n",
    "    list_of_tup.append((Dict, PLACES[i]))\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    \n",
    "# Formatting the files    \n",
    "    \n",
    "for i in range(len(list_of_tup)):\n",
    "    temp = list_of_tup[i]\n",
    "    \n",
    "    place = temp[1]\n",
    "    trend = temp[0]\n",
    "\n",
    "    year = []\n",
    "    counts = []\n",
    "    place1 = []\n",
    "    \n",
    "    for key,val in trend.items():\n",
    "        \n",
    "\n",
    "        year.append(key)\n",
    "        counts.append(trend[key])\n",
    "        place1.append(place)\n",
    "        \n",
    "    year   = np.array(year)\n",
    "    counts = np.array(counts)\n",
    "    place1 = np.array(place1)\n",
    "\n",
    "    year   = year.reshape((len(year),1))\n",
    "    counts = counts.reshape((len(counts),1))\n",
    "    place1 = place1.reshape((len(place1),1))\n",
    "\n",
    "    temp_data = np.concatenate((place1, year, counts), axis =1)\n",
    "    dataframe = pd.DataFrame(data = temp_data, columns = ['Place', 'Year', 'Count'])\n",
    "    dataframe = dataframe.sort_values(by = 'Year')\n",
    "\n",
    "    if i == 0:\n",
    "        final_dataframe = dataframe.copy()\n",
    "    else:\n",
    "        final_dataframe = pd.concat([final_dataframe, dataframe], axis=0)       \n",
    "        final_dataframe.reset_index(drop = True, inplace= True)\n",
    "        \n",
    "        \n",
    "    print(i)\n",
    "\n",
    "    \n",
    "\n",
    "final_dataframe.to_csv('All_cities_1451-1500.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the list of subjects\n",
    "\n",
    "Dict = {'Religious': 19820, 'Ordinances and Edicts': 9339, 'Classical Authors': 5922, 'Political Tracts': 5596, \n",
    "        'History and Chronicles': 3489, 'Jurisprudence': 3400, 'Poetry': 3388, 'Literature': 3270, 'Medical Texts': 2579, \n",
    "        'Music': 2310, 'News Books': 2256, 'Educational Books': 1879, 'Drama': 1422, 'Bibles (including parts)': 1365, \n",
    "        'Philosophy and Morality': 1289, 'Science and Mathematics': 946, 'Funeral orations': 714, 'Academic Dissertations': 689,\n",
    "        'Government and Political Theory': 641, 'Dialectics and Rhetoric': 596, 'Travel': 583, 'Dictionaries': 510, \n",
    "        'Calendars and Prognostications': 396, 'Astrology and Cosmography': 386, 'Agriculture': 301, \n",
    "        'Adages and Emblem books': 297, 'Economics': 285, 'Heraldic Works and Genealogies': 234, \n",
    "        'Military Handbooks': 225, 'Art and Architecture': 179, 'Linguistics and Philology': 169, 'Book Trade': 126, \n",
    "        'Witchcraft and Demonology': 81, 'Etiquette and Courtesy': 61, 'Culinary Arts': 38, 'Games and Recreations': 37,\n",
    "        'Wedding pamphlets': 21, 'Marriage, the debate on women': 1}\n",
    "\n",
    "SUBJECTS = []\n",
    "\n",
    "for key,val in Dict.items():\n",
    "    SUBJECTS.append(key)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(SUBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1824000\n",
      "1824000\n"
     ]
    }
   ],
   "source": [
    "# Combining the csv files \n",
    "\n",
    "names = ['50','100','200','250','300','350','400','480']\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in range(len(names)):\n",
    "    \n",
    "    dataframe = pd.read_csv('All_cities_1451-1600_with_all_subjects_' + str(names[i]) + '.csv')\n",
    "    count    += len(dataframe['Subject'])\n",
    "    \n",
    "    if i == 0:\n",
    "        final_dataframe = dataframe.copy()\n",
    "    else:\n",
    "        final_dataframe = pd.concat([final_dataframe, dataframe], axis=0)       \n",
    "        final_dataframe.reset_index(drop = True, inplace= True)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "print(count)\n",
    "print(len(final_dataframe['Subject']))\n",
    "  \n",
    "\n",
    "\n",
    "final_dataframe.to_csv('All_480_cities_with_all_subjects_from_1451-1600.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('All_480_cities_with_all_subjects_from_1451-1600.csv')\n",
    "len(data['Place'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
